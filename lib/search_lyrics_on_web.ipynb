{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本物のコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check if the programming is running\n",
      "check if the programming is running\n",
      "check if the programming is running\n",
      "check if the programming is running\n",
      "check if the programming is running\n",
      "check if the programming is running\n",
      "check if the programming is running\n",
      "check if the programming is running\n",
      "check if the programming is running\n",
      "check if the programming is running\n",
      "check if the programming is running\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-6a776bd381e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"check if the programming is running\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#2秒待ってから実行\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# DBに接続する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 無限ループの中で任意秒待つためのモジュール\n",
    "import time\n",
    "# MySQLに接続するためのモジュール\n",
    "import mysql.connector\n",
    "# ウェブサイトからHTMLを取ってくるためのモジュール\n",
    "import urllib\n",
    "# 曲名で検索した結果を表示してる画面のURLのもと(URLtoSearchByTitle[1] には後から曲の名前が入る)\n",
    "listURLtoSearchByTitle = [\"https://www.uta-net.com/search/?Aselect=2&Keyword=\", \"\", \"&Bselect=4\"]\n",
    "# HTMLパーサー\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "while True:\n",
    "    print(\"check if the programming is running\")\n",
    "    time.sleep(2) #2秒待ってから実行\n",
    "    \n",
    "    # DBに接続する\n",
    "    connection = mysql.connector.connect(user='root', host='localhost', database='lyrics_database2')\n",
    "    # カーソルを取得する\n",
    "    cursor = connection.cursor()\n",
    "    # クエリの実行\n",
    "    cursor.execute(\n",
    "        \"SELECT singer.id, singer.name, song.title, song.lyric \" +\n",
    "        \"FROM song \" +\n",
    "        \"INNER JOIN singer_song ON singer_song.song_id = song.id \" +\n",
    "        \"INNER JOIN composer ON composer.id = song.composer_id \" +\n",
    "        \"INNER JOIN singer ON singer.id = singer_song.singer_id;\"\n",
    "    )\n",
    "    # 実行結果をすべて取得\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    for row in rows:\n",
    "        lyrics = row[3]\n",
    "        # 歌詞がNULLの時は歌詞をweb(Uta-Net)に取りに行く\n",
    "        if lyrics is None:\n",
    "            ###### まずは曲名で検索 ######\n",
    "            singerName = row[2]\n",
    "            # 配列 listURLtoSearchByTitleを成型して、文字列stringURLtoSearchByTitleにする\n",
    "            listURLtoSearchByTitle[1] = singerName\n",
    "            stringURLtoSearchByTitle = \"\".join(listURLtoSearchByTitle)\n",
    "            # HTMLファイルを開く\n",
    "            data = urllib.request.urlopen(stringURLtoSearchByTitle)\n",
    "            # HTMLの取得\n",
    "            html = data.read()\n",
    "            # HTMLファイルを閉じる\n",
    "            data.close()\n",
    "            # BeautifulSoupオブジェクトの作成\n",
    "            soup = BeautifulSoup(html)\n",
    "            # 取得したいタグの種類とクラス属性を指定し、歌手名をリストで取得\n",
    "            singerNames = soup.findAll(\"td\", class_=\"td2\")\n",
    "            \n",
    "            \n",
    "            ### 曲名を元に検索して出てきたものの中から歌手名も一致するものを選択する ###\n",
    "            # for文の最初で+1するため、indicatorの初期値は0ではなく-1にしておく\n",
    "            indicator = -1\n",
    "            # targetの定義\n",
    "            target = \"\"\n",
    "            \n",
    "            \n",
    "            ## 検索したい曲のページのURLの取得\n",
    "            for td in singerNames:\n",
    "                indicator += 1\n",
    "                targetSingerName = td.find(\"a\").text\n",
    "                if targetSingerName == singerName:\n",
    "                    urls = soup.findAll(\"td\", class_ = \"side td1\")\n",
    "                    kk = -1\n",
    "                    for td2 in urls:\n",
    "                        kk += 1\n",
    "                        targetURL = td2.find(\"a\").attrs['href']\n",
    "                        if kk == indicator:\n",
    "                            target = \"https://www.uta-net.com\" + targetURL\n",
    "                            break\n",
    "                    break\n",
    "                #else: # 曲名で検索した結果がなかった時\n",
    "                    \n",
    "                    \n",
    "            ## 検索したいページを開いてから歌詞を手に入れるまでのながれ\n",
    "            data = urllib.request.urlopen(target)\n",
    "            # HTMLの取得\n",
    "            html = data.read()\n",
    "            # HTMLファイルを閉じる\n",
    "            data.close()\n",
    "            # BeautifulSoupオブジェクトの作成\n",
    "            soup = BeautifulSoup(html, \"lxml\")\n",
    "            # 取得したいタグの種類とクラス属性を指定し、歌詞を取得\n",
    "            lyricsFromHTML = soup.find(\"div\", id = \"kashi_area\")\n",
    "            # lyricsFromHTMLを成型(文字列にしてからhtmlタグを削除)\n",
    "            stringLyricsFromHTML = str(lyricsFromHTML)\n",
    "            parsedLyrics = stringLyricsFromHTML.replace('<div id=\"kashi_area\">', \"\").replace(\"</div>\", \"\").replace(\"<br/>\", \"\")\n",
    "            \n",
    "            \n",
    "            # DBに歌詞を書き込み##################################\n",
    "            cursor.execute(\n",
    "                #update文に変える\n",
    "                \"UPDATE lyrics_database.song SET lyric = '\" + parsedLyrics + \"'\" +\n",
    "                \"WHERE id = \" + int(row[0]) + \";\"\n",
    "            )\n",
    "            connection.commit()\n",
    "            \n",
    "    cursor.close\n",
    "    connection.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コードがちゃんと動くかを、DBに接続しないでテスト中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大丈夫だよ　見上げれば　もう大丈夫ほら　七色の橋やっと同じ空の下で　笑えるね靴紐を結びなおす時　風が僕らの背中を押す空がこぼした光の向こうに　あのユメの続きを描こう左胸の奥が高鳴る　期待と不安が脈を打つ本当に大丈夫かな　全て乗り越えてゆけるかな大丈夫だよ　見上げれば　もう大丈夫ほら　七色の橋涙を流しきると　空に架かるねぇ見えるでしょ　はるか彼方に僕にも見える　君と同じの二つの空が　いま一つになるやっと同じ空の下で　笑えるね別々の空を持って生まれた　記憶を映し出す空君には君の物語があり　僕の知らない涙があるもしかしたら僕が笑う頃に　君は泣いてたのかもしれない似たような喜びはあるけれど　同じ悲しみはきっとない「約束」で未来を縁取り　コトバで飾り付けをする君は確かな明日を　きっと　誰より　欲しがってた巡る季節のひとつのように悲しい時は　悲しいままに幸せになることを　急がないで大丈夫だよ　ここにいるから大丈夫だよ　どこにもいかないまた走り出す時は　君といっしょ「涙のない世界にも　その橋は架かりますか？」壁に刻まれた落書きは　ダレカの字によく似てた悲しみを遠ざけることで　君は橋を架けようとしたけれど　今　傘を捨てて　目をつぶるだいじょうぶ大丈夫だよ　見上げれば　もう大丈夫ほら　七色の橋涙を流し終えた君の空にねぇ見えるでしょ　色鮮やかに僕にも見える　君と同じの絆という名の虹が架かったねそして二つの空がやっと　やっと　一つになって僕らを走らせるんだ\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "# 曲名で検索した結果を表示してる画面のURLのもと(URLtoSearchByTitle[1] には後から曲の名前が入る)\n",
    "# HTMLパーサー\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "data = urllib.request.urlopen(\"https://www.uta-net.com/search/?Aselect=2&Keyword=%E8%99%B9&Bselect=4\")\n",
    "# HTMLの取得\n",
    "html = data.read()\n",
    "# HTMLファイルを閉じる\n",
    "data.close()\n",
    "# BeautifulSoupオブジェクトの作成\n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "# 取得したいタグの種類とクラス属性を指定し、歌手名をリストで取得\n",
    "singerNames = soup.findAll(\"td\", class_ = \"td2\")\n",
    "# for文の最初に+1するため、indicatorの初期値は0ではなく-1にしておく\n",
    "indicator = -1\n",
    "# targetの定義\n",
    "target = \"\"\n",
    "\n",
    "## 検索したい曲のページのURLの取得\n",
    "for td in singerNames:\n",
    "    indicator += 1\n",
    "    targetSingerName = td.find(\"a\").text\n",
    "    if targetSingerName == \"Aqua Timez\":\n",
    "        urls = soup.findAll(\"td\", class_ = \"side td1\")\n",
    "        kk = -1\n",
    "        for td2 in urls:\n",
    "            kk += 1\n",
    "            targetURL = td2.find(\"a\").attrs['href']\n",
    "            if kk == indicator:\n",
    "                target = \"https://www.uta-net.com\" + targetURL\n",
    "                break\n",
    "        break\n",
    "\n",
    "\n",
    "## 検索したいページを開いてから歌詞を手に入れるまでのながれ\n",
    "data = urllib.request.urlopen(target)\n",
    "# HTMLの取得\n",
    "html = data.read()\n",
    "# HTMLファイルを閉じる\n",
    "data.close()\n",
    "# BeautifulSoupオブジェクトの作成\n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "# 取得したいタグの種類とクラス属性を指定し、歌詞を取得\n",
    "lyricsFromHTML = soup.find(\"div\", id = \"kashi_area\")\n",
    "# lyricsFromHTMLを成型(文字列にしてからhtmlタグを削除)\n",
    "stringLyricsFromHTML = str(lyricsFromHTML)\n",
    "parsedLyrics = stringLyricsFromHTML.replace('<div id=\"kashi_area\">', \"\").replace(\"</div>\", \"\").replace(\"<br/>\", \"\")\n",
    "\n",
    "\n",
    "print(parsedLyrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
